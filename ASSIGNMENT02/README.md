# DH110-22F-SC
## Pilot Usability Test

### Introduction

The Funding the Ocean website is used as a way to provide those involved in/interested in conservation efforts with information and resources. It provides access to a funding map of ocean conservation efforts, a database/library of case studies, affinity groups, news, and report repositories on ocean conservation, information about the SDG goals, and a place to share knowledge.

Several usability issues with the site were found while conducting a heuristic analysis on the site:

- First, I found that the website did not follow the Match Between System and the Real world, as it used a lot of internal jargon that might be confusing for an average user, especially in the funding map page and the resource center page. 
- Second,the website also struggled with the recognition rather than recall heurstic, especially on the funding map. The feature was very confusing to use and there was an unfortunate learning curve for that page.. 
- The website also had problems with aesthetic and minimalist design. The large banners with eye-catching images and lack of contrast between them and the CTA buttons caused me to miss them/scroll past them often.


Given these problems, I conducted a usability test to evaluate how well the user is able to complete certain tasks using the website. Through this test, I intend to see whether the participant struggles to complete the tasks due to any issues that were found during the heuristic analysis or issues that were overlooked. Along with the usability issues, I found that there were a lack of websites that provided resources and information for people who are wanting to get involved in ocean conservation locally, so if I find that the user struggled with this task on the site, it would validate the need to design/redesign a better site for this purpose. In order to test the usability of the site, I created three tasks for the participant:
1. Find information about a local organization in Los Angeles
2. Finding which resources FundingTheOcean is providing
3. Find events to learn about ocean conservation efforts you can attend virtually


## Methodology

The usability test took place in the quiet kitchen of my apartment in Los Angeles, California. I used my own Macbook Pro laptop as a recording device, and used Zoom to record the test. The participant went through and signed the informed consent before the survey, completed pre- and post- test questionanaires, and attemped to perform three tasks on the site. The links below include the Google form used to faciliate and record responses in the test and a recording of the participant's facial expressions and the screen as they went through the site. This usability test is a pilot test.

## UT Survey

https://forms.gle/XYGZVzCUDAmLWTN19

## UT Video

https://drive.google.com/file/d/1oDAk4f494GyffGg-OII9XXoDu3N5TJaj/view?usp=sharing

## Reflection

While conducting the usability test, I found that there were many things I learned, both about problems the user encountered with the website, as well as with what went smoothly or did not while going through the usability test itself. I found that during the first task, as expected the participant had trouble with narrowing down to local organizations, and specifically ones that had opportunities for community involvement. I was also trying to test the heuristic of match between system and the real world, as that page had a lot of internal jargon I thought would be confusing for the user. Althought the particpant did have some trouble with navigating this feature and performing the task, it was hard to tell if it was due to that heuristic because being overwhelmed with internal jargon might be something happening unconsciously or not something that the user could volcalize well. However, I did find an issue with Visibility of System Status heuristic that I overlooked during the heuristic analysis initially--when the user searches something on the search bar, it will only work if it shows up on the drop down menu and you can click it. If it doesn't, the search simply dissapears and the user is not sure if anything happened. The user easily completed the second task. The third task was an interesting case--the participant was asked to find and list 2 events that took place "virtually" they could attend (as there were none in California). However, only one event they listed was virtual, and it did not seem like they were looking for something on the site that said "virtual". Clearly, they missed where the first event actually said "virtual", otherwise they would have looked for another event with the same indication. However, I was not sure if this was a problem with the site not having a better location indicator for the events, or if it was a problem with me not emphasizing the instructions clearly enough. In this situation, however, I did not want to correct her and compromise the integrity of the test by interfering. Therefore, in the future, I think that making the instructions for the task as detailed as possible (without giving too much away) will be something to work on. One aspect of the test that went very smoothly was that I encouraged the participant to think aloud during the tasks, so she was very vocal during the usability test which can provide valuable data for the project. Overall, I learned a lot from the pilot UT that I believe will help my project, as well as my skills in future usability testing. 


